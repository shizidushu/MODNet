{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_dataset import BaseDataset\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from util import gen_trimap, gen_trimap_with_dilate, gen_trimap_with_dilate_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = '/home/ubuntu/data/workspace/deeplabv3_plus/people_segmentation'\n",
    "# ds = BaseDataset(root_dir, img_dir=\"images\", alpha_dir=\"masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = BaseDataset( \"/home/ubuntu/data/yong/projects/MODNet/data/PPM-100\",\n",
    "#         \"image\",\n",
    "#         \"matte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = BaseDataset( \"/home/ubuntu/data/yong/projects/P3M/data/P3M-10k/train\",\n",
    "#         \"blurred_image\",\n",
    "#         \"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290 samples\n"
     ]
    }
   ],
   "source": [
    "ds = BaseDataset( \"/home/ubuntu/data/yong/dataset/Human-Segmentation-Dataset\",\n",
    "        \"Training_Images\",\n",
    "        \"Ground_Truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = BaseDataset( \"/home/ubuntu/data/yong/dataset/human_matting_dataset_kaggle\",\n",
    "#         \"JPEGImages\",\n",
    "#         \"SegmentationClassPNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = BaseDataset( \"/home/ubuntu/data/yong/dataset/segmentation_full_body_mads_dataset_1192_img\",\n",
    "#         \"images\",\n",
    "#         \"masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = BaseDataset( \"/home/ubuntu/data/yong/dataset/RealWorldPortrait-636\",\n",
    "#         \"image\",\n",
    "#         \"alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = BaseDataset(\"/home/ubuntu/data/yong/dataset/people_segmentation\",\n",
    "#         \"images\",\n",
    "#         \"profiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = random.randint(0, len(ds) - 1)\n",
    "sample = ds[rand_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_path, weight, img, trimap, alpha = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.array(Image.open(alpha_path))\n",
    "if alpha.shape[-1] == 4:\n",
    "    if len(np.unique(alpha[..., -1])) == 1:\n",
    "        alpha = alpha[..., :-1]\n",
    "alpha = alpha[..., -1] if len(alpha.shape) > 2 else alpha\n",
    "\n",
    "if 'profile' in alpha_path:\n",
    "    alpha = 255 - alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.amax(alpha) <= 1:\n",
    "    alpha = alpha * 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=640x480 at 0x7F0A8851BC10>"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.array(alpha, dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(alpha):\n",
    "    foreground = alpha > 0.0\n",
    "    res = None\n",
    "    res = Image.fromarray(foreground).getbbox()\n",
    "    if res is None:\n",
    "        left, upper, right, ylower = 0, 0, alpha.shape[1], alpha.shape[0]\n",
    "    else:\n",
    "        left, upper, right, ylower = res\n",
    "    return (left, upper, right, ylower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(alpha):\n",
    "    rect = get_bbox(alpha)\n",
    "    rect_width = rect[2] - rect[0]\n",
    "    rect_height = rect[3] - rect[1]\n",
    "    res = cv2.rectangle(np.array(alpha, dtype=np.uint8), rect[:2], rect[2:], color = 128, thickness =2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res  = draw_bbox(alpha)\n",
    "# Image.fromarray(np.array(res, dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_crop_by_bbox(alpha, ref_size = 512, random_scale = 1.5):\n",
    "    rect = get_bbox(alpha)\n",
    "    rect_width = rect[2] - rect[0]\n",
    "    rect_height = rect[3] - rect[1]\n",
    "\n",
    "    im_h, im_w = alpha.shape\n",
    "\n",
    "    # 将BBOX裁剪出来\n",
    "    width_pad = int(rect_width / 2.0)\n",
    "    height_pad = int(rect_height / 2.0)\n",
    "    pad_for_long_side = max(width_pad, height_pad)\n",
    "    pad_for_short_side = pad_for_long_side + int(abs(rect_height - rect_width) / 2.0)\n",
    "    if im_h >= im_w:\n",
    "        x_start = max(rect[0] - pad_for_short_side, 0)\n",
    "        x_end = min(rect[2] + pad_for_short_side, im_w - 1)\n",
    "        y_start = max(rect[1] - pad_for_long_side, 0)\n",
    "        y_end = min(rect[3] + pad_for_long_side, im_h - 1)\n",
    "    else:\n",
    "        x_start = max(rect[0] - pad_for_long_side, 0)\n",
    "        x_end = min(rect[2] + pad_for_long_side, im_w - 1)\n",
    "        y_start = max(rect[1] - pad_for_short_side, 0)\n",
    "        y_end = min(rect[3] + pad_for_short_side, im_h - 1)\n",
    "    alpha = alpha[y_start:y_end, x_start:x_end, ...]\n",
    "\n",
    "    # 将短边缩短到512\n",
    "    im_h, im_w = alpha.shape\n",
    "    # 非标准512x512图片，resize到短边为ref_size~ref_size*random_scale\n",
    "    # 然后center crop 或 random crop\n",
    "    if not (im_h == ref_size and im_w == ref_size):\n",
    "        random_size = np.random.randint(ref_size, int(ref_size * random_scale))\n",
    "        if im_w >= im_h:\n",
    "            im_rh = random_size\n",
    "            im_rw = int(im_w / im_h * random_size)\n",
    "        elif im_w < im_h:\n",
    "            im_rw = random_size\n",
    "            im_rh = int(im_h / im_w * random_size)\n",
    "\n",
    "    # img = cv2.resize(img, (im_rw, im_rh), interpolation=cv2.INTER_LINEAR)\n",
    "    alpha = cv2.resize(alpha, (im_rw, im_rh), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # random crop\n",
    "    x0 = random.randint(0, im_rw - ref_size)\n",
    "    y0 = random.randint(0, im_rh - ref_size)\n",
    "    # img = img[y0:y0 + ref_size, x0:x0 + ref_size, ...]\n",
    "    alpha = alpha[y0:y0 + ref_size, x0:x0 + ref_size]\n",
    "    \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=512x512 at 0x7F0A8851B430>"
      ]
     },
     "execution_count": 1078,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = resize_and_crop_by_bbox(alpha)\n",
    "print(res.shape)\n",
    "Image.fromarray(np.array(res, dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hrnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "598fd409a443807d6a2169d707c3340b253e6d0666aad806a3124513fbe3224b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
